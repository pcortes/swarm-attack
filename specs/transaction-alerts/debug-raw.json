{
  "type": "result",
  "subtype": "success",
  "is_error": false,
  "duration_ms": 266639,
  "duration_api_ms": 275734,
  "num_turns": 1,
  "result": "<<<DISPOSITIONS_START>>>\n[\n  {\n    \"issue_id\": \"R2-1\",\n    \"original_issue\": \"Quiet-hours behavior is undefined even though the preferences model exposes quiet-hour configuration. Without a decision on whether alerts are queued, dropped, or routed to alternate channels the delivery pipeline in Section 2.3 cannot be implemented deterministically.\",\n    \"classification\": \"ACCEPT\",\n    \"reasoning\": \"This is a valid gap. The spec defines quiet_hours fields in UserAlertPreferences but never specifies what happens to alerts during those hours. Implementers need a clear decision to build the delivery pipeline. I'll specify that during quiet hours, non-critical alerts are queued until quiet hours end, while CRITICAL alerts (fraud) are delivered immediately regardless of quiet hours.\",\n    \"action_taken\": \"Added Section 2.5 'Quiet Hours Behavior' specifying that CRITICAL alerts bypass quiet hours, while HIGH/NORMAL/LOW alerts are queued for delivery when quiet hours end. Updated data flow in Section 2.3 to include quiet hours check.\",\n    \"resolved\": true,\n    \"semantic_key\": \"behavior_hours_quiet\",\n    \"repeat_of\": null,\n    \"consecutive_rejections\": 0\n  },\n  {\n    \"issue_id\": \"R2-2\",\n    \"original_issue\": \"There is no alert-rate limiting or per-user throttling strategy. In a fraud scenario a single compromised account could emit hundreds of alerts per minute, overwhelming users and violating the PRD goal of maintaining trust.\",\n    \"classification\": \"ACCEPT\",\n    \"reasoning\": \"Valid concern for user experience and system stability. A compromised account generating hundreds of transactions would flood the user with alerts, causing alert fatigue and potentially masking the real fraud. Rate limiting is a reasonable operational control. I'll add per-user rate limits with aggregation for excess alerts.\",\n    \"action_taken\": \"Added Section 2.6 'Alert Rate Limiting' with per-user limits (20 alerts/hour, 100 alerts/day), aggregation behavior for excess alerts, and CRITICAL alert exemption. Added rate_limit metrics to monitoring.\",\n    \"resolved\": true,\n    \"semantic_key\": \"limiting_rate_throttling\",\n    \"repeat_of\": null,\n    \"consecutive_rejections\": 0\n  },\n  {\n    \"issue_id\": \"R2-3\",\n    \"original_issue\": \"The alert queue relies on a single Redis sorted set but the spec does not address persistence, replication, or replay semantics. A Redis failover or eviction would silently drop queued alerts, making it impossible to meet the 30-second SLA or guarantee delivery.\",\n    \"classification\": \"PARTIAL\",\n    \"reasoning\": \"The concern about queue durability is valid\u2014losing alerts during failover would violate the SLA. However, the suggestion to add Kafka-backed fallback is over-engineering for a queue that should be nearly empty most of the time (alerts are processed within seconds). I'll specify Redis persistence and cluster requirements, plus a lightweight recovery mechanism using the alerts_history table.\",\n    \"action_taken\": \"Added Section 7.4 'Queue Durability' specifying Redis AOF persistence, 3-node cluster with automatic failover, and recovery mechanism that replays undelivered alerts from alerts_history on startup. Did not add Kafka fallback as it adds unnecessary complexity.\",\n    \"resolved\": true,\n    \"semantic_key\": \"durability_queue_redis\",\n    \"repeat_of\": null,\n    \"consecutive_rejections\": 0\n  },\n  {\n    \"issue_id\": \"R2-4\",\n    \"original_issue\": \"The PRD targets a 40% fraud-loss reduction, but the spec only lists latency/operational metrics. There is no plan for capturing prevented-loss data or tying alerts back to confirmed fraud outcomes, so success against the business goal cannot be measured.\",\n    \"classification\": \"DEFER\",\n    \"reasoning\": \"The PRD lists 'Reduce fraud losses by 40%' as a goal, but measuring this requires linking alerts to downstream fraud disposition systems, dispute outcomes, and financial loss tracking\u2014none of which are within the scope of this alerting system. This is a cross-functional analytics concern that requires coordination with fraud operations, disputes, and finance teams. The alerting system's job is to emit events; measuring business impact is a separate analytics initiative.\",\n    \"action_taken\": \"Added a note in Section 9.3 about emitting alert_action_taken events (user blocked card, reported fraud, dismissed) for downstream analytics. Actual fraud loss measurement requires a separate analytics project integrating multiple data sources.\",\n    \"resolved\": false,\n    \"semantic_key\": \"fraud_loss_measurement\",\n    \"repeat_of\": null,\n    \"consecutive_rejections\": 0\n  }\n]\n<<<DISPOSITIONS_END>>>\n\n<<<SPEC_START>>>\n# Engineering Spec: Transaction Alerts\n\n## 1. Overview\n\n### 1.1 Purpose\n\nTransaction Alerts is a real-time notification system that monitors user accounts for suspicious transaction activity and delivers alerts through multiple channels (push notifications, SMS, and email). The system enables users to configure personalized alert thresholds and temporarily snooze alerts when needed (e.g., while traveling).\n\n### 1.2 Scope\n\n**In Scope:**\n- Real-time transaction monitoring with <30 second alert delivery\n- Multi-channel notification delivery (push, SMS, email)\n- User-configurable alert rules and thresholds\n- System default rules for immediate value (>$500 transactions, high fraud scores)\n- Alert snooze functionality with automatic expiration\n- Quiet hours support with priority-based handling\n- Per-user alert rate limiting to prevent alert fatigue\n- Integration with existing notification service\n- Transaction data retention policy enforcement (90-day limit)\n- Support for 10M users and 100M transactions/day\n\n**Out of Scope:**\n- Fraud detection ML models (assumes upstream fraud scoring exists)\n- Payment blocking/hold functionality\n- User authentication and account management\n- Notification service implementation (existing service)\n- Transaction processing (reads from existing transaction stream)\n- False positive analytics and dashboards (emits events for downstream systems)\n- Fraud loss measurement and business impact analytics (emits events for downstream systems)\n\n### 1.3 Success Criteria\n\n| Criterion | Metric | Target |\n|-----------|--------|--------|\n| Alert latency | P99 delivery time | < 30 seconds |\n| User adoption | Opt-in rate | > 60% |\n| Alert quality | False positive rate | < 5% |\n| System scale | Concurrent users | 10M users |\n| Throughput | Daily transactions | 100M/day |\n| Availability | System uptime | 99.9% |\n\n---\n\n## 2. Architecture\n\n### 2.1 High-Level Design\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           Transaction Alerts System                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n                                    \u2502\n                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                   \u2502      Transaction Stream         \u2502\n                   \u2502    (Kafka/Event Source)         \u2502\n                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Transaction Processor                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502  \u2502  Transaction    \u2502  \u2502  Rule Engine    \u2502  \u2502  Alert          \u2502             \u2502\n\u2502  \u2502  Consumer       \u2502\u2500\u2500\u2502  Evaluator      \u2502\u2500\u2500\u2502  Generator      \u2502             \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          Alert Delivery Pipeline                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502  \u2502  Alert Queue    \u2502  \u2502  Channel        \u2502  \u2502  Notification   \u2502             \u2502\n\u2502  \u2502  (Priority)     \u2502\u2500\u2500\u2502  Router         \u2502\u2500\u2500\u2502  Service        \u2502             \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           Storage Layer                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502  \u2502  User           \u2502  \u2502  Alert          \u2502  \u2502  Alert          \u2502             \u2502\n\u2502  \u2502  Preferences    \u2502  \u2502  Rules          \u2502  \u2502  History        \u2502             \u2502\n\u2502  \u2502  (Redis)        \u2502  \u2502  (PostgreSQL)   \u2502  \u2502  (TimescaleDB)  \u2502             \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### 2.2 Components\n\n| Component | Responsibility | Technology |\n|-----------|---------------|------------|\n| Transaction Consumer | Consume transactions from event stream | Kafka Consumer |\n| Rule Engine Evaluator | Evaluate user rules against transactions | In-memory rules cache + PostgreSQL |\n| Alert Generator | Create alert objects from triggered rules | Python service |\n| Alert Queue | Priority queue for alert delivery | Redis Sorted Set (clustered, AOF) |\n| Channel Router | Route alerts to appropriate notification channels | Python service |\n| Notification Service | Deliver notifications via push/SMS/email | Existing service (integration) |\n| User Preferences Store | Cache user preferences for fast lookup | Redis |\n| Alert Rules Store | Persist user-defined alert rules | PostgreSQL |\n| Alert History Store | Time-series storage for alert history | TimescaleDB (90-day retention) |\n\n### 2.3 Data Flow\n\n1. **Transaction Ingestion**\n   - Transaction events arrive via Kafka topic `transactions.processed`\n   - Consumer deserializes and validates transaction schema\n   - Transaction enriched with user_id and account metadata\n\n2. **Rule Evaluation**\n   - Fetch user's active alert rules from cache (Redis) or database\n   - Include system default rules (see Section 3.3)\n   - Check if user has active snooze period\n   - Evaluate each rule against transaction attributes\n   - Generate alert if any rule triggers\n\n3. **Alert Generation**\n   - Create Alert object with transaction details and triggered rule\n   - Assign priority based on rule severity and transaction amount\n   - Check rate limits (see Section 2.6)\n   - Enqueue to priority queue for delivery\n\n4. **Alert Delivery**\n   - Dequeue alerts by priority\n   - Check quiet hours (see Section 2.5)\n   - Route to user's preferred channels\n   - Call notification service for each channel\n   - Record delivery status in alert history\n\n5. **Cleanup**\n   - Background job purges alerts older than 90 days\n   - Expired snooze periods are automatically cleared\n\n### 2.4 Snooze Behavior\n\nWhen a user has an active snooze period, the system handles alerts as follows:\n\n**Behavior:** Alerts are **dropped** (not queued for later delivery).\n\n**Rationale:** Users snooze alerts during travel or known activity periods. Delivering a backlog of alerts when snooze ends would be overwhelming and the alerts would be stale. Users can review transaction history if they want to see what happened during the snooze period.\n\n**Implementation:**\n1. During rule evaluation, check for active snooze periods\n2. If snooze affects the triggered rule/channel, skip alert generation\n3. Record a delivery record with status `snoozed` for audit purposes\n4. Transaction remains in history and is visible via `/api/v1/alerts/history`\n\n**Partial Snooze:** If a snooze only covers specific channels (e.g., SMS snoozed but push active), alerts are delivered to non-snoozed channels only.\n\n### 2.5 Quiet Hours Behavior\n\nWhen a user has quiet hours configured, the system handles alerts based on priority:\n\n**Behavior by Priority:**\n\n| Priority | During Quiet Hours | Rationale |\n|----------|-------------------|-----------|\n| CRITICAL | Delivered immediately | Potential fraud requires immediate attention |\n| HIGH | Queued until quiet hours end | Important but not urgent |\n| NORMAL | Queued until quiet hours end | Standard alerts can wait |\n| LOW | Queued until quiet hours end | Informational alerts |\n\n**Implementation:**\n1. During alert delivery, check if current time falls within user's quiet hours (respecting timezone)\n2. If CRITICAL priority: bypass quiet hours, deliver immediately\n3. If non-CRITICAL: add to quiet hours queue with delivery_after timestamp\n4. Background job processes quiet hours queue when user's quiet hours end\n5. Queued alerts are delivered in priority order when quiet hours end\n\n**Queue Behavior:**\n- Alerts queued during quiet hours are delivered in batches when quiet hours end\n- If more than 10 alerts are queued, they are aggregated into a summary notification followed by individual alerts\n- Quiet hours queue uses the same Redis infrastructure as the main alert queue\n\n**Edge Cases:**\n- If quiet hours span midnight (e.g., 22:00-07:00), system correctly handles the date boundary\n- If user changes quiet hours while alerts are queued, existing queue is not affected\n\n### 2.6 Alert Rate Limiting\n\nTo prevent alert fatigue and protect users from notification floods during fraud events:\n\n**Rate Limits:**\n\n| Limit Type | Threshold | Window | Action When Exceeded |\n|------------|-----------|--------|---------------------|\n| Per-user hourly | 20 alerts | 1 hour | Aggregate into summary |\n| Per-user daily | 100 alerts | 24 hours | Aggregate into summary |\n| Per-channel hourly | 10 alerts | 1 hour | Route to alternate channel |\n\n**Exemptions:**\n- CRITICAL priority alerts are never rate-limited (fraud must always notify)\n- System rules (fraud_score >= 0.7) bypass rate limits\n\n**Aggregation Behavior:**\nWhen rate limits are exceeded:\n1. Individual alerts continue to be recorded in alerts_history\n2. User receives a summary notification: \"You have 15 new transaction alerts. Tap to view.\"\n3. Summary is sent on the least-used channel to avoid channel fatigue\n4. Rate limit counters reset at the top of each hour/day (UTC)\n\n**Implementation:**\n```python\n@dataclass\nclass UserRateLimitState:\n    user_id: str\n    hourly_count: int = 0\n    daily_count: int = 0\n    hourly_reset_at: datetime\n    daily_reset_at: datetime\n    \ndef check_rate_limit(user_id: str, priority: AlertPriority) -> RateLimitResult:\n    \"\"\"Check if alert should be delivered or aggregated.\"\"\"\n    if priority == AlertPriority.CRITICAL:\n        return RateLimitResult(allowed=True, reason=\"critical_exempt\")\n    \n    state = get_user_rate_state(user_id)\n    \n    if state.hourly_count >= 20:\n        return RateLimitResult(allowed=False, reason=\"hourly_limit\", aggregate=True)\n    if state.daily_count >= 100:\n        return RateLimitResult(allowed=False, reason=\"daily_limit\", aggregate=True)\n    \n    return RateLimitResult(allowed=True)\n```\n\n**Monitoring:**\n- `alerts_rate_limited_total` counter tracks how often limits are hit\n- `alerts_aggregated_total` counter tracks summary notifications sent\n\n---\n\n## 3. Data Models\n\n### 3.1 New Models\n\n```python\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nfrom enum import Enum\nfrom typing import Optional, Literal\nfrom decimal import Decimal\nimport uuid\n\n\nclass AlertChannel(Enum):\n    \"\"\"Supported notification channels.\"\"\"\n    PUSH = \"push\"\n    SMS = \"sms\"\n    EMAIL = \"email\"\n\n\nclass AlertPriority(Enum):\n    \"\"\"Alert priority levels for queue ordering.\"\"\"\n    CRITICAL = 1  # Immediate delivery (fraud, large amounts)\n    HIGH = 2      # Fast delivery (threshold exceeded)\n    NORMAL = 3    # Standard delivery (informational)\n    LOW = 4       # Batch delivery (summaries)\n\n\nclass RuleOperator(Enum):\n    \"\"\"Comparison operators for rule evaluation.\"\"\"\n    GREATER_THAN = \"gt\"\n    GREATER_THAN_OR_EQUAL = \"gte\"\n    LESS_THAN = \"lt\"\n    LESS_THAN_OR_EQUAL = \"lte\"\n    EQUALS = \"eq\"\n    NOT_EQUALS = \"neq\"\n    IN = \"in\"\n    NOT_IN = \"not_in\"\n\n\nclass RuleField(Enum):\n    \"\"\"Transaction fields available for rule conditions.\"\"\"\n    AMOUNT = \"amount\"\n    MERCHANT_CATEGORY = \"merchant_category\"\n    MERCHANT_NAME = \"merchant_name\"\n    COUNTRY = \"country\"\n    TRANSACTION_TYPE = \"transaction_type\"\n    IS_INTERNATIONAL = \"is_international\"\n    IS_CARD_PRESENT = \"is_card_present\"\n    FRAUD_SCORE = \"fraud_score\"  # Upstream fraud score (0.0 - 1.0)\n\n\nclass RuleType(Enum):\n    \"\"\"Distinguishes system-managed rules from user-created rules.\"\"\"\n    SYSTEM = \"system\"  # Auto-provisioned, cannot be deleted by user\n    USER = \"user\"      # User-created, fully manageable\n\n\n@dataclass\nclass RuleCondition:\n    \"\"\"Single condition in an alert rule.\"\"\"\n    field: RuleField\n    operator: RuleOperator\n    value: str | int | float | list[str]  # Type depends on field\n\n    def evaluate(self, transaction: \"Transaction\") -> bool:\n        \"\"\"Evaluate this condition against a transaction.\"\"\"\n        tx_value = getattr(transaction, self.field.value, None)\n        if tx_value is None:\n            return False\n\n        if self.operator == RuleOperator.GREATER_THAN:\n            return tx_value > self.value\n        elif self.operator == RuleOperator.GREATER_THAN_OR_EQUAL:\n            return tx_value >= self.value\n        elif self.operator == RuleOperator.LESS_THAN:\n            return tx_value < self.value\n        elif self.operator == RuleOperator.LESS_THAN_OR_EQUAL:\n            return tx_value <= self.value\n        elif self.operator == RuleOperator.EQUALS:\n            return tx_value == self.value\n        elif self.operator == RuleOperator.NOT_EQUALS:\n            return tx_value != self.value\n        elif self.operator == RuleOperator.IN:\n            return tx_value in self.value\n        elif self.operator == RuleOperator.NOT_IN:\n            return tx_value not in self.value\n        return False\n\n\n@dataclass\nclass AlertRule:\n    \"\"\"User-defined rule for triggering alerts.\"\"\"\n    rule_id: str                                    # UUID\n    user_id: str                                    # User who owns this rule\n    name: str                                       # Human-readable name\n    description: str                                # Rule description\n    conditions: list[RuleCondition]                 # All conditions must match (AND)\n    channels: list[AlertChannel]                    # Channels to notify\n    priority: AlertPriority = AlertPriority.NORMAL  # Default priority\n    rule_type: RuleType = RuleType.USER             # System vs user rule\n    is_active: bool = True                          # Can be disabled without deletion\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    updated_at: datetime = field(default_factory=datetime.utcnow)\n\n    def evaluate(self, transaction: \"Transaction\") -> bool:\n        \"\"\"Evaluate all conditions against a transaction (AND logic).\"\"\"\n        if not self.is_active:\n            return False\n        return all(condition.evaluate(transaction) for condition in self.conditions)\n\n\n@dataclass\nclass UserAlertPreferences:\n    \"\"\"User's global alert preferences.\"\"\"\n    user_id: str\n    alerts_enabled: bool = True                     # Master switch\n    default_channels: list[AlertChannel] = field(\n        default_factory=lambda: [AlertChannel.PUSH]\n    )\n    quiet_hours_start: Optional[int] = None         # Hour (0-23), None = disabled\n    quiet_hours_end: Optional[int] = None           # Hour (0-23)\n    quiet_hours_timezone: str = \"UTC\"               # User's timezone\n    min_amount_for_alert: Decimal = Decimal(\"0\")    # Minimum transaction amount\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    updated_at: datetime = field(default_factory=datetime.utcnow)\n\n\n@dataclass\nclass AlertSnooze:\n    \"\"\"Temporary snooze period for alerts.\"\"\"\n    snooze_id: str                                  # UUID\n    user_id: str\n    reason: Optional[str] = None                    # e.g., \"traveling\"\n    channels_snoozed: list[AlertChannel] = field(  # Empty = all channels\n        default_factory=list\n    )\n    rules_snoozed: list[str] = field(              # Rule IDs, empty = all rules\n        default_factory=list\n    )\n    start_at: datetime = field(default_factory=datetime.utcnow)\n    end_at: datetime = field(                       # Default 24 hours\n        default_factory=lambda: datetime.utcnow() + timedelta(hours=24)\n    )\n    created_at: datetime = field(default_factory=datetime.utcnow)\n\n    def is_active(self, at_time: Optional[datetime] = None) -> bool:\n        \"\"\"Check if snooze is currently active.\"\"\"\n        check_time = at_time or datetime.utcnow()\n        return self.start_at <= check_time <= self.end_at\n\n    def affects_rule(self, rule_id: str) -> bool:\n        \"\"\"Check if this snooze affects a specific rule.\"\"\"\n        return len(self.rules_snoozed) == 0 or rule_id in self.rules_snoozed\n\n    def affects_channel(self, channel: AlertChannel) -> bool:\n        \"\"\"Check if this snooze affects a specific channel.\"\"\"\n        return len(self.channels_snoozed) == 0 or channel in self.channels_snoozed\n\n\n@dataclass\nclass Transaction:\n    \"\"\"Transaction data from upstream system.\"\"\"\n    transaction_id: str\n    user_id: str\n    account_id: str\n    amount: Decimal\n    currency: str\n    merchant_name: str\n    merchant_category: str\n    country: str\n    transaction_type: Literal[\"purchase\", \"withdrawal\", \"transfer\", \"refund\"]\n    is_international: bool\n    is_card_present: bool\n    fraud_score: float                              # 0.0 - 1.0 from upstream\n    timestamp: datetime\n    metadata: dict = field(default_factory=dict)    # Additional attributes\n\n\n@dataclass\nclass Alert:\n    \"\"\"Generated alert ready for delivery.\"\"\"\n    alert_id: str                                   # UUID\n    user_id: str\n    transaction_id: str\n    rule_id: str                                    # Rule that triggered this alert\n    rule_name: str\n    channels: list[AlertChannel]\n    priority: AlertPriority\n    title: str                                      # Short title for notification\n    body: str                                       # Full message body\n    amount: Decimal\n    merchant_name: str\n    transaction_timestamp: datetime\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    delivered_at: Optional[datetime] = None\n    delivery_status: dict[str, str] = field(        # channel -> status\n        default_factory=dict\n    )\n\n    def mark_delivered(self, channel: AlertChannel, status: str) -> None:\n        \"\"\"Record delivery status for a channel.\"\"\"\n        self.delivery_status[channel.value] = status\n        if all(s == \"delivered\" for s in self.delivery_status.values()):\n            self.delivered_at = datetime.utcnow()\n\n\n@dataclass\nclass AlertDeliveryRecord:\n    \"\"\"Record of alert delivery attempt.\"\"\"\n    record_id: str                                  # UUID\n    alert_id: str\n    channel: AlertChannel\n    status: Literal[\"pending\", \"delivered\", \"failed\", \"snoozed\", \"quiet_hours\", \"rate_limited\"]\n    attempted_at: datetime\n    delivered_at: Optional[datetime] = None\n    error_message: Optional[str] = None\n    retry_count: int = 0\n    snoozed_by: Optional[str] = None               # snooze_id if status=snoozed\n    deliver_after: Optional[datetime] = None       # For quiet hours queuing\n```\n\n### 3.2 Schema Changes\n\n**PostgreSQL Migrations:**\n\n```sql\n-- Migration: 001_create_alert_rules\nCREATE TABLE alert_rules (\n    rule_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    user_id VARCHAR(64) NOT NULL,\n    name VARCHAR(255) NOT NULL,\n    description TEXT,\n    conditions JSONB NOT NULL,\n    channels TEXT[] NOT NULL,\n    priority VARCHAR(20) NOT NULL DEFAULT 'normal',\n    rule_type VARCHAR(20) NOT NULL DEFAULT 'user',\n    is_active BOOLEAN NOT NULL DEFAULT true,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n\n    CONSTRAINT valid_priority CHECK (priority IN ('critical', 'high', 'normal', 'low')),\n    CONSTRAINT valid_channels CHECK (channels <@ ARRAY['push', 'sms', 'email']::TEXT[]),\n    CONSTRAINT valid_rule_type CHECK (rule_type IN ('system', 'user'))\n);\n\nCREATE INDEX idx_alert_rules_user_id ON alert_rules(user_id);\nCREATE INDEX idx_alert_rules_active ON alert_rules(user_id, is_active) WHERE is_active = true;\n\n\n-- Migration: 002_create_user_alert_preferences\nCREATE TABLE user_alert_preferences (\n    user_id VARCHAR(64) PRIMARY KEY,\n    alerts_enabled BOOLEAN NOT NULL DEFAULT true,\n    default_channels TEXT[] NOT NULL DEFAULT ARRAY['push'],\n    quiet_hours_start SMALLINT CHECK (quiet_hours_start >= 0 AND quiet_hours_start <= 23),\n    quiet_hours_end SMALLINT CHECK (quiet_hours_end >= 0 AND quiet_hours_end <= 23),\n    quiet_hours_timezone VARCHAR(50) NOT NULL DEFAULT 'UTC',\n    min_amount_for_alert DECIMAL(15,2) NOT NULL DEFAULT 0,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n\n\n-- Migration: 003_create_alert_snooze\nCREATE TABLE alert_snooze (\n    snooze_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    user_id VARCHAR(64) NOT NULL,\n    reason TEXT,\n    channels_snoozed TEXT[],\n    rules_snoozed UUID[],\n    start_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    end_at TIMESTAMPTZ NOT NULL,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n\n    CONSTRAINT valid_snooze_period CHECK (end_at > start_at)\n);\n\nCREATE INDEX idx_alert_snooze_user_active ON alert_snooze(user_id, end_at)\n    WHERE end_at > NOW();\n\n\n-- Migration: 004_create_alerts_history (TimescaleDB hypertable)\nCREATE TABLE alerts_history (\n    alert_id UUID NOT NULL,\n    user_id VARCHAR(64) NOT NULL,\n    transaction_id VARCHAR(64) NOT NULL,\n    rule_id UUID NOT NULL,\n    rule_name VARCHAR(255) NOT NULL,\n    channels TEXT[] NOT NULL,\n    priority VARCHAR(20) NOT NULL,\n    title VARCHAR(500) NOT NULL,\n    body TEXT NOT NULL,\n    amount DECIMAL(15,2) NOT NULL,\n    merchant_name VARCHAR(255) NOT NULL,\n    transaction_timestamp TIMESTAMPTZ NOT NULL,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    delivered_at TIMESTAMPTZ,\n    delivery_status JSONB NOT NULL DEFAULT '{}'::JSONB,\n\n    PRIMARY KEY (alert_id, created_at)\n);\n\n-- Convert to TimescaleDB hypertable for efficient time-series queries\nSELECT create_hypertable('alerts_history', 'created_at');\n\n-- Automatic retention policy: drop data older than 90 days\nSELECT add_retention_policy('alerts_history', INTERVAL '90 days');\n\nCREATE INDEX idx_alerts_history_user ON alerts_history(user_id, created_at DESC);\nCREATE INDEX idx_alerts_history_transaction ON alerts_history(transaction_id);\n\n\n-- Migration: 005_create_delivery_records\nCREATE TABLE alert_delivery_records (\n    record_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    alert_id UUID NOT NULL,\n    channel VARCHAR(20) NOT NULL,\n    status VARCHAR(20) NOT NULL,\n    attempted_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    delivered_at TIMESTAMPTZ,\n    error_message TEXT,\n    retry_count INT NOT NULL DEFAULT 0,\n    snoozed_by UUID,  -- References snooze_id if status='snoozed'\n    deliver_after TIMESTAMPTZ,  -- For quiet hours queuing\n\n    CONSTRAINT valid_status CHECK (status IN ('pending', 'delivered', 'failed', 'snoozed', 'quiet_hours', 'rate_limited'))\n);\n\nCREATE INDEX idx_delivery_records_alert ON alert_delivery_records(alert_id);\nCREATE INDEX idx_delivery_records_pending ON alert_delivery_records(status)\n    WHERE status = 'pending';\nCREATE INDEX idx_delivery_records_quiet_hours ON alert_delivery_records(deliver_after)\n    WHERE status = 'quiet_hours' AND deliver_after IS NOT NULL;\n\n\n-- Migration: 006_create_rate_limit_state\nCREATE TABLE user_rate_limit_state (\n    user_id VARCHAR(64) PRIMARY KEY,\n    hourly_count INT NOT NULL DEFAULT 0,\n    daily_count INT NOT NULL DEFAULT 0,\n    hourly_reset_at TIMESTAMPTZ NOT NULL,\n    daily_reset_at TIMESTAMPTZ NOT NULL,\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n```\n\n### 3.3 System Default Rules\n\nEvery user receives the following system-managed rules upon account creation. These rules ensure immediate value per PRD requirements and cannot be deleted (only disabled).\n\n**Default Rule 1: Large Transaction Alert**\n\n| Property | Value |\n|----------|-------|\n| Name | Large Transaction |\n| Description | Alerts for transactions over $500 |\n| Condition | `amount >= 500` |\n| Priority | HIGH |\n| Channels | User's default channels (initially: push) |\n| Rule Type | SYSTEM |\n\n**Default Rule 2: Suspicious Activity Alert**\n\n| Property | Value |\n|----------|-------|\n| Name | Suspicious Activity |\n| Description | Alerts for transactions with high fraud scores |\n| Condition | `fraud_score >= 0.7` |\n| Priority | CRITICAL |\n| Channels | All enabled channels (push, SMS, email) |\n| Rule Type | SYSTEM |\n\n**Provisioning:**\n- System rules are created during user onboarding via the `provision_default_rules(user_id)` function\n- Rules are stored in `alert_rules` table with `rule_type = 'system'`\n- API prevents deletion of system rules (returns 403 FORBIDDEN)\n- Users may disable system rules via the toggle endpoint\n- Users may customize thresholds by creating their own rules\n\n**Implementation:**\n\n```python\nSYSTEM_DEFAULT_RULES = [\n    {\n        \"name\": \"Large Transaction\",\n        \"description\": \"Alerts for transactions over $500\",\n        \"conditions\": [\n            {\"field\": \"amount\", \"operator\": \"gte\", \"value\": 500.00}\n        ],\n        \"priority\": \"high\",\n        \"rule_type\": \"system\",\n    },\n    {\n        \"name\": \"Suspicious Activity\",\n        \"description\": \"Alerts for transactions with high fraud scores\",\n        \"conditions\": [\n            {\"field\": \"fraud_score\", \"operator\": \"gte\", \"value\": 0.7}\n        ],\n        \"priority\": \"critical\",\n        \"rule_type\": \"system\",\n    },\n]\n\nasync def provision_default_rules(user_id: str, preferences: UserAlertPreferences) -> list[AlertRule]:\n    \"\"\"Create system default rules for a new user.\"\"\"\n    rules = []\n    for rule_def in SYSTEM_DEFAULT_RULES:\n        rule = AlertRule(\n            rule_id=str(uuid.uuid4()),\n            user_id=user_id,\n            name=rule_def[\"name\"],\n            description=rule_def[\"description\"],\n            conditions=[RuleCondition(**c) for c in rule_def[\"conditions\"]],\n            channels=preferences.default_channels if rule_def[\"priority\"] == \"high\" \n                     else list(AlertChannel),  # Critical rules use all channels\n            priority=AlertPriority[rule_def[\"priority\"].upper()],\n            rule_type=RuleType.SYSTEM,\n        )\n        rules.append(rule)\n    return rules\n```\n\n---\n\n## 4. API Design\n\n### 4.1 Endpoints\n\n| Method | Path | Description |\n|--------|------|-------------|\n| GET | /api/v1/alerts/preferences | Get user's alert preferences |\n| PUT | /api/v1/alerts/preferences | Update user's alert preferences |\n| GET | /api/v1/alerts/rules | List user's alert rules |\n| POST | /api/v1/alerts/rules | Create a new alert rule |\n| GET | /api/v1/alerts/rules/{rule_id} | Get a specific rule |\n| PUT | /api/v1/alerts/rules/{rule_id} | Update a rule |\n| DELETE | /api/v1/alerts/rules/{rule_id} | Delete a rule (user rules only) |\n| POST | /api/v1/alerts/rules/{rule_id}/toggle | Enable/disable a rule |\n| GET | /api/v1/alerts/snooze | Get active snooze periods |\n| POST | /api/v1/alerts/snooze | Create a snooze period |\n| DELETE | /api/v1/alerts/snooze/{snooze_id} | Cancel a snooze |\n| GET | /api/v1/alerts/history | List alert history |\n| GET | /api/v1/alerts/{alert_id} | Get a specific alert |\n\n### 4.2 Request/Response Schemas\n\n**GET /api/v1/alerts/preferences**\n\nResponse:\n```json\n{\n  \"user_id\": \"usr_123456\",\n  \"alerts_enabled\": true,\n  \"default_channels\": [\"push\", \"email\"],\n  \"quiet_hours\": {\n    \"enabled\": true,\n    \"start\": 22,\n    \"end\": 7,\n    \"timezone\": \"America/New_York\"\n  },\n  \"min_amount_for_alert\": \"10.00\"\n}\n```\n\n**PUT /api/v1/alerts/preferences**\n\nRequest:\n```json\n{\n  \"alerts_enabled\": true,\n  \"default_channels\": [\"push\", \"sms\"],\n  \"quiet_hours\": {\n    \"enabled\": true,\n    \"start\": 23,\n    \"end\": 8,\n    \"timezone\": \"America/Los_Angeles\"\n  },\n  \"min_amount_for_alert\": \"25.00\"\n}\n```\n\nResponse: Same as GET\n\n**POST /api/v1/alerts/rules**\n\nRequest:\n```json\n{\n  \"name\": \"Large transactions\",\n  \"description\": \"Alert me for transactions over $500\",\n  \"conditions\": [\n    {\n      \"field\": \"amount\",\n      \"operator\": \"gte\",\n      \"value\": 500.00\n    }\n  ],\n  \"channels\": [\"push\", \"sms\"],\n  \"priority\": \"high\"\n}\n```\n\nResponse:\n```json\n{\n  \"rule_id\": \"rul_abc123def456\",\n  \"user_id\": \"usr_123456\",\n  \"name\": \"Large transactions\",\n  \"description\": \"Alert me for transactions over $500\",\n  \"conditions\": [\n    {\n      \"field\": \"amount\",\n      \"operator\": \"gte\",\n      \"value\": 500.00\n    }\n  ],\n  \"channels\": [\"push\", \"sms\"],\n  \"priority\": \"high\",\n  \"rule_type\": \"user\",\n  \"is_active\": true,\n  \"created_at\": \"2025-12-15T10:30:00Z\",\n  \"updated_at\": \"2025-12-15T10:30:00Z\"\n}\n```\n\n**GET /api/v1/alerts/rules**\n\nResponse includes both system and user rules:\n```json\n{\n  \"rules\": [\n    {\n      \"rule_id\": \"rul_sys_001\",\n      \"name\": \"Large Transaction\",\n      \"description\": \"Alerts for transactions over $500\",\n      \"conditions\": [{\"field\": \"amount\", \"operator\": \"gte\", \"value\": 500.00}],\n      \"channels\": [\"push\"],\n      \"priority\": \"high\",\n      \"rule_type\": \"system\",\n      \"is_active\": true,\n      \"created_at\": \"2025-12-01T00:00:00Z\",\n      \"updated_at\": \"2025-12-01T00:00:00Z\"\n    },\n    {\n      \"rule_id\": \"rul_sys_002\",\n      \"name\": \"Suspicious Activity\",\n      \"description\": \"Alerts for transactions with high fraud scores\",\n      \"conditions\": [{\"field\": \"fraud_score\", \"operator\": \"gte\", \"value\": 0.7}],\n      \"channels\": [\"push\", \"sms\", \"email\"],\n      \"priority\": \"critical\",\n      \"rule_type\": \"system\",\n      \"is_active\": true,\n      \"created_at\": \"2025-12-01T00:00:00Z\",\n      \"updated_at\": \"2025-12-01T00:00:00Z\"\n    }\n  ]\n}\n```\n\n**DELETE /api/v1/alerts/rules/{rule_id}**\n\nFor system rules, returns 403:\n```json\n{\n  \"error\": {\n    \"code\": \"CANNOT_DELETE_SYSTEM_RULE\",\n    \"message\": \"System rules cannot be deleted. Use the toggle endpoint to disable.\",\n    \"details\": {\n      \"rule_id\": \"rul_sys_001\",\n      \"rule_type\": \"system\"\n    }\n  }\n}\n```\n\n**POST /api/v1/alerts/snooze**\n\nRequest:\n```json\n{\n  \"reason\": \"Traveling internationally\",\n  \"duration_hours\": 72,\n  \"channels_snoozed\": [],\n  \"rules_snoozed\": []\n}\n```\n\nResponse:\n```json\n{\n  \"snooze_id\": \"snz_xyz789\",\n  \"user_id\": \"usr_123456\",\n  \"reason\": \"Traveling internationally\",\n  \"channels_snoozed\": [],\n  \"rules_snoozed\": [],\n  \"start_at\": \"2025-12-15T10:30:00Z\",\n  \"end_at\": \"2025-12-18T10:30:00Z\",\n  \"created_at\": \"2025-12-15T10:30:00Z\"\n}\n```\n\n**GET /api/v1/alerts/history**\n\nQuery Parameters:\n- `limit` (int, default: 50, max: 100)\n- `offset` (int, default: 0)\n- `start_date` (ISO date, optional)\n- `end_date` (ISO date, optional)\n- `rule_id` (UUID, optional)\n- `include_snoozed` (bool, default: false) - Include transactions that occurred during snooze\n\nResponse:\n```json\n{\n  \"alerts\": [\n    {\n      \"alert_id\": \"alt_abc123\",\n      \"transaction_id\": \"txn_xyz789\",\n      \"rule_id\": \"rul_abc123def456\",\n      \"rule_name\": \"Large transactions\",\n      \"title\": \"Large Transaction Alert\",\n      \"body\": \"A transaction of $750.00 at Amazon.com was detected\",\n      \"amount\": \"750.00\",\n      \"merchant_name\": \"Amazon.com\",\n      \"channels\": [\"push\", \"sms\"],\n      \"priority\": \"high\",\n      \"transaction_timestamp\": \"2025-12-15T10:25:00Z\",\n      \"created_at\": \"2025-12-15T10:25:05Z\",\n      \"delivered_at\": \"2025-12-15T10:25:08Z\",\n      \"delivery_status\": {\n        \"push\": \"delivered\",\n        \"sms\": \"delivered\"\n      }\n    }\n  ],\n  \"pagination\": {\n    \"limit\": 50,\n    \"offset\": 0,\n    \"total\": 127\n  }\n}\n```\n\n### 4.3 Error Responses\n\n```json\n{\n  \"error\": {\n    \"code\": \"RULE_NOT_FOUND\",\n    \"message\": \"Alert rule with ID 'rul_invalid' not found\",\n    \"details\": {\n      \"rule_id\": \"rul_invalid\"\n    }\n  }\n}\n```\n\n| Error Code | HTTP Status | Description |\n|------------|-------------|-------------|\n| INVALID_REQUEST | 400 | Malformed request body |\n| INVALID_RULE_CONDITION | 400 | Invalid rule condition syntax |\n| RULE_NOT_FOUND | 404 | Rule does not exist |\n| SNOOZE_NOT_FOUND | 404 | Snooze period does not exist |\n| CANNOT_DELETE_SYSTEM_RULE | 403 | Attempted to delete a system rule |\n| MAX_RULES_EXCEEDED | 429 | User has too many rules (limit: 50) |\n| MAX_SNOOZE_EXCEEDED | 429 | User has too many active snoozes |\n| INTERNAL_ERROR | 500 | Internal server error |\n\n---\n\n## 5. Implementation Plan\n\n### 5.1 Tasks\n\n| # | Task | Dependencies | Size | Description |\n|---|------|--------------|------|-------------|\n| 1 | Create data models | None | M | Implement all dataclasses in `models/alert_models.py` |\n| 2 | Database migrations | None | S | Create PostgreSQL and TimescaleDB migrations |\n| 3 | Alert rules repository | 1, 2 | M | CRUD operations for alert rules with caching |\n| 4 | User preferences repository | 1, 2 | S | CRUD for user preferences with Redis cache |\n| 5 | Snooze repository | 1, 2 | S | Snooze period management |\n| 6 | Rule evaluation engine | 1 | M | Evaluate conditions against transactions |\n| 7 | Transaction consumer | 1 | M | Kafka consumer for transaction events |\n| 8 | Alert generator service | 1, 6 | M | Generate alerts from triggered rules |\n| 9 | Alert queue manager | 1 | S | Priority queue for alert delivery |\n| 10 | Channel router | 1 | M | Route alerts to notification channels |\n| 11 | Notification service integration | 10 | M | Integrate with existing notification service |\n| 12 | Alert history repository | 1, 2 | M | TimescaleDB storage with retention |\n| 13 | REST API endpoints | 3, 4, 5, 12 | L | All API endpoints with validation |\n| 14 | Alert processor orchestrator | 7, 8, 9, 10 | L | Coordinate the full pipeline |\n| 15 | Default rules provisioning | 3, 4 | S | System default rules on user creation |\n| 16 | Quiet hours handler | 4, 9 | M | Queue and deliver alerts respecting quiet hours |\n| 17 | Rate limiter | 4, 8 | M | Per-user rate limiting with aggregation |\n| 18 | Monitoring and metrics | 14 | M | Prometheus metrics, latency tracking |\n| 19 | Unit tests | 1-18 | L | Comprehensive unit test coverage |\n| 20 | Integration tests | 19 | L | End-to-end pipeline tests |\n| 21 | Load testing | 20 | M | Verify 100M transactions/day throughput |\n\n### 5.2 File Changes\n\n**New Files:**\n```\nsrc/\n\u251c\u2500\u2500 alerts/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 models.py                    # Task 1: Data models\n\u2502   \u251c\u2500\u2500 constants.py                 # Task 15: System default rules definitions\n\u2502   \u251c\u2500\u2500 repositories/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 rules_repository.py      # Task 3: Alert rules CRUD\n\u2502   \u2502   \u251c\u2500\u2500 preferences_repository.py # Task 4: User preferences\n\u2502   \u2502   \u251c\u2500\u2500 snooze_repository.py     # Task 5: Snooze management\n\u2502   \u2502   \u2514\u2500\u2500 history_repository.py    # Task 12: Alert history\n\u2502   \u251c\u2500\u2500 services/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 rule_engine.py           # Task 6: Rule evaluation\n\u2502   \u2502   \u251c\u2500\u2500 alert_generator.py       # Task 8: Alert generation\n\u2502   \u2502   \u251c\u2500\u2500 channel_router.py        # Task 10: Channel routing\n\u2502   \u2502   \u251c\u2500\u2500 notification_adapter.py  # Task 11: Notification integration\n\u2502   \u2502   \u251c\u2500\u2500 user_provisioning.py     # Task 15: Default rule provisioning\n\u2502   \u2502   \u251c\u2500\u2500 quiet_hours_handler.py   # Task 16: Quiet hours logic\n\u2502   \u2502   \u2514\u2500\u2500 rate_limiter.py          # Task 17: Rate limiting\n\u2502   \u251c\u2500\u2500 consumers/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 transaction_consumer.py  # Task 7: Kafka consumer\n\u2502   \u251c\u2500\u2500 queue/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 alert_queue.py           # Task 9: Priority queue\n\u2502   \u251c\u2500\u2500 orchestrator.py              # Task 14: Pipeline coordinator\n\u2502   \u2514\u2500\u2500 api/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 routes.py                # Task 13: API routes\n\u2502       \u251c\u2500\u2500 schemas.py               # Task 13: Pydantic schemas\n\u2502       \u2514\u2500\u2500 handlers.py              # Task 13: Request handlers\n\u251c\u2500\u2500 migrations/\n\u2502   \u251c\u2500\u2500 001_create_alert_rules.sql\n\u2502   \u251c\u2500\u2500 002_create_user_alert_preferences.sql\n\u2502   \u251c\u2500\u2500 003_create_alert_snooze.sql\n\u2502   \u251c\u2500\u2500 004_create_alerts_history.sql\n\u2502   \u251c\u2500\u2500 005_create_delivery_records.sql\n\u2502   \u2514\u2500\u2500 006_create_rate_limit_state.sql\ntests/\n\u251c\u2500\u2500 alerts/\n\u2502   \u251c\u2500\u2500 test_models.py               # Task 19\n\u2502   \u251c\u2500\u2500 test_rule_engine.py          # Task 19\n\u2502   \u251c\u2500\u2500 test_alert_generator.py      # Task 19\n\u2502   \u251c\u2500\u2500 test_repositories.py         # Task 19\n\u2502   \u251c\u2500\u2500 test_api.py                  # Task 19\n\u2502   \u251c\u2500\u2500 test_default_rules.py        # Task 19: System rules tests\n\u2502   \u251c\u2500\u2500 test_quiet_hours.py          # Task 19: Quiet hours tests\n\u2502   \u251c\u2500\u2500 test_rate_limiter.py         # Task 19: Rate limit tests\n\u2502   \u2514\u2500\u2500 integration/\n\u2502       \u251c\u2500\u2500 test_full_pipeline.py    # Task 20\n\u2502       \u2514\u2500\u2500 test_load.py             # Task 21\n```\n\n**Modified Files:**\n```\nsrc/\n\u251c\u2500\u2500 config.py                        # Add alerts configuration section\n\u251c\u2500\u2500 main.py                          # Register alert API routes\n\u2514\u2500\u2500 services/notification_service.py # Add alert delivery methods (if needed)\n```\n\n---\n\n## 6. Testing Strategy\n\n### 6.1 Unit Tests\n\n| Component | Test Cases | Coverage Target |\n|-----------|------------|-----------------|\n| Data models | Serialization, validation, equality | 95% |\n| Rule conditions | All operators, edge cases, fraud_score | 100% |\n| Rule engine | Single/multiple conditions, inactive rules, system rules | 90% |\n| Alert generator | Title/body formatting, priority assignment | 90% |\n| Repositories | CRUD operations, cache invalidation | 85% |\n| Queue manager | Priority ordering, dequeue behavior | 90% |\n| API handlers | Request validation, error responses, system rule protection | 85% |\n| Default provisioning | New user gets system rules, idempotency | 90% |\n| Quiet hours handler | Queueing, delivery timing, CRITICAL bypass | 90% |\n| Rate limiter | Limit enforcement, aggregation, CRITICAL bypass | 90% |\n\n**Key Unit Tests:**\n\n```python\n# test_rule_engine.py\ndef test_amount_greater_than_condition():\n    \"\"\"Rule triggers when transaction amount exceeds threshold.\"\"\"\n    rule = AlertRule(\n        rule_id=\"test_rule\",\n        user_id=\"user_123\",\n        name=\"Large tx\",\n        description=\"\",\n        conditions=[\n            RuleCondition(\n                field=RuleField.AMOUNT,\n                operator=RuleOperator.GREATER_THAN,\n                value=500\n            )\n        ],\n        channels=[AlertChannel.PUSH]\n    )\n\n    tx_over = Transaction(amount=Decimal(\"750.00\"), ...)\n    tx_under = Transaction(amount=Decimal(\"100.00\"), ...)\n\n    assert rule.evaluate(tx_over) == True\n    assert rule.evaluate(tx_under) == False\n\ndef test_fraud_score_triggers_alert():\n    \"\"\"High fraud score triggers suspicious activity rule.\"\"\"\n    rule = AlertRule(\n        rule_id=\"fraud_rule\",\n        user_id=\"user_123\",\n        name=\"Suspicious Activity\",\n        description=\"\",\n        conditions=[\n            RuleCondition(\n                field=RuleField.FRAUD_SCORE,\n                operator=RuleOperator.GREATER_THAN_OR_EQUAL,\n                value=0.7\n            )\n        ],\n        channels=[AlertChannel.PUSH, AlertChannel.SMS, AlertChannel.EMAIL],\n        priority=AlertPriority.CRITICAL,\n        rule_type=RuleType.SYSTEM\n    )\n\n    tx_suspicious = Transaction(fraud_score=0.85, amount=Decimal(\"50.00\"), ...)\n    tx_normal = Transaction(fraud_score=0.2, amount=Decimal(\"50.00\"), ...)\n\n    assert rule.evaluate(tx_suspicious) == True\n    assert rule.evaluate(tx_normal) == False\n\ndef test_multiple_conditions_require_all_match():\n    \"\"\"All conditions must match for rule to trigger (AND logic).\"\"\"\n    rule = AlertRule(\n        conditions=[\n            RuleCondition(RuleField.AMOUNT, RuleOperator.GREATER_THAN, 100),\n            RuleCondition(RuleField.IS_INTERNATIONAL, RuleOperator.EQUALS, True),\n        ],\n        ...\n    )\n\n    tx_both = Transaction(amount=Decimal(\"500\"), is_international=True, ...)\n    tx_amount_only = Transaction(amount=Decimal(\"500\"), is_international=False, ...)\n\n    assert rule.evaluate(tx_both) == True\n    assert rule.evaluate(tx_amount_only) == False\n\ndef test_snooze_blocks_alert():\n    \"\"\"Active snooze prevents alert generation.\"\"\"\n    snooze = AlertSnooze(\n        user_id=\"user_123\",\n        start_at=datetime.utcnow() - timedelta(hours=1),\n        end_at=datetime.utcnow() + timedelta(hours=23),\n    )\n\n    assert snooze.is_active() == True\n\ndef test_expired_snooze_allows_alert():\n    \"\"\"Expired snooze does not block alerts.\"\"\"\n    snooze = AlertSnooze(\n        user_id=\"user_123\",\n        start_at=datetime.utcnow() - timedelta(hours=25),\n        end_at=datetime.utcnow() - timedelta(hours=1),\n    )\n\n    assert snooze.is_active() == False\n\n# test_default_rules.py\ndef test_new_user_receives_system_rules():\n    \"\"\"New users are provisioned with system default rules.\"\"\"\n    user_id = \"new_user_123\"\n    preferences = UserAlertPreferences(user_id=user_id)\n    \n    rules = await provision_default_rules(user_id, preferences)\n    \n    assert len(rules) == 2\n    assert all(r.rule_type == RuleType.SYSTEM for r in rules)\n    assert any(r.name == \"Large Transaction\" for r in rules)\n    assert any(r.name == \"Suspicious Activity\" for r in rules)\n\ndef test_cannot_delete_system_rule():\n    \"\"\"API returns 403 when attempting to delete system rule.\"\"\"\n    response = client.delete(\"/api/v1/alerts/rules/rul_sys_001\")\n    assert response.status_code == 403\n    assert response.json()[\"error\"][\"code\"] == \"CANNOT_DELETE_SYSTEM_RULE\"\n\ndef test_can_disable_system_rule():\n    \"\"\"System rules can be disabled via toggle endpoint.\"\"\"\n    response = client.post(\"/api/v1/alerts/rules/rul_sys_001/toggle\")\n    assert response.status_code == 200\n    assert response.json()[\"is_active\"] == False\n\n# test_quiet_hours.py\ndef test_critical_alerts_bypass_quiet_hours():\n    \"\"\"CRITICAL priority alerts are delivered during quiet hours.\"\"\"\n    user = create_user_with_quiet_hours(start=22, end=7)\n    alert = create_alert(priority=AlertPriority.CRITICAL)\n    \n    result = quiet_hours_handler.process(alert, current_hour=23)\n    \n    assert result.action == \"deliver_now\"\n    assert result.queued == False\n\ndef test_high_priority_alerts_queued_during_quiet_hours():\n    \"\"\"HIGH priority alerts are queued during quiet hours.\"\"\"\n    user = create_user_with_quiet_hours(start=22, end=7)\n    alert = create_alert(priority=AlertPriority.HIGH)\n    \n    result = quiet_hours_handler.process(alert, current_hour=23)\n    \n    assert result.action == \"queue\"\n    assert result.deliver_after.hour == 7\n\ndef test_queued_alerts_delivered_when_quiet_hours_end():\n    \"\"\"Queued alerts are delivered when quiet hours end.\"\"\"\n    # Queue 5 alerts during quiet hours\n    alerts = [create_alert(priority=AlertPriority.NORMAL) for _ in range(5)]\n    \n    # Simulate quiet hours ending\n    delivered = quiet_hours_handler.process_queue(user_id, current_hour=7)\n    \n    assert len(delivered) == 5\n\n# test_rate_limiter.py\ndef test_rate_limit_aggregates_excess_alerts():\n    \"\"\"Alerts beyond rate limit are aggregated into summary.\"\"\"\n    user_id = \"user_123\"\n    \n    # Send 25 alerts (5 over hourly limit of 20)\n    results = [rate_limiter.check(user_id, AlertPriority.NORMAL) for _ in range(25)]\n    \n    allowed = [r for r in results if r.allowed]\n    aggregated = [r for r in results if r.aggregate]\n    \n    assert len(allowed) == 20\n    assert len(aggregated) == 5\n\ndef test_critical_alerts_bypass_rate_limit():\n    \"\"\"CRITICAL alerts are never rate limited.\"\"\"\n    user_id = \"user_123\"\n    \n    # Exhaust rate limit with normal alerts\n    for _ in range(25):\n        rate_limiter.check(user_id, AlertPriority.NORMAL)\n    \n    # CRITICAL should still be allowed\n    result = rate_limiter.check(user_id, AlertPriority.CRITICAL)\n    \n    assert result.allowed == True\n    assert result.reason == \"critical_exempt\"\n```\n\n### 6.2 Integration Tests\n\n| Scenario | Description | Validation |\n|----------|-------------|------------|\n| Full pipeline happy path | Transaction \u2192 Alert \u2192 Delivery | Alert delivered < 30s |\n| System rule triggers on new user | $600 transaction for new user | Alert delivered via default rules |\n| Fraud score triggers critical alert | Transaction with fraud_score=0.8 | Critical alert on all channels |\n| Snooze blocks delivery | User snoozes, transaction occurs | No alert delivered, status='snoozed' |\n| Snooze partial channel | Snooze SMS only | Push delivered, SMS snoozed |\n| Quiet hours queues non-critical | HIGH alert during quiet hours | Queued, delivered after quiet hours |\n| Quiet hours bypassed for CRITICAL | CRITICAL alert during quiet hours | Delivered immediately |\n| Rate limit triggers aggregation | 25 alerts in 1 hour | First 20 delivered, 5 aggregated |\n| Rule update propagates | Update rule, new transaction | New rule evaluated |\n| Multi-channel delivery | Rule with 3 channels | All channels receive alert |\n| Retention enforcement | Query 91-day-old alert | Alert not found |\n| High volume throughput | 1000 transactions/second | All processed < 30s |\n| Queue recovery after restart | Simulate restart with pending alerts | Pending alerts recovered and delivered |\n\n### 6.3 Edge Cases\n\n| Edge Case | Expected Behavior |\n|-----------|-------------------|\n| User with no rules | System default rules still evaluate |\n| User with alerts_enabled=false | No alert generated |\n| All rules inactive (including system) | No alert generated |\n| Transaction exactly at threshold | Rule triggers (>=) |\n| Multiple rules trigger same transaction | One alert per rule |\n| Snooze covers some channels | Non-snoozed channels alerted |\n| Notification service timeout | Retry with backoff |\n| Notification service returns 500 | Retry with backoff, then fail |\n| User deletes rule after alert generated | Alert still delivered |\n| Concurrent snooze create/delete | Last write wins |\n| Transaction with null merchant_category | Rule condition skipped |\n| Transaction with fraud_score exactly 0.7 | Suspicious Activity rule triggers |\n| Quiet hours span midnight (22:00-07:00) | Correctly handles date boundary |\n| Rate limit reset at hour boundary | Counter resets, new alerts allowed |\n| CRITICAL alert during rate limit | Delivered without aggregation |\n\n---\n\n## 7. Risks and Mitigations\n\n| Risk | Impact | Likelihood | Mitigation |\n|------|--------|------------|------------|\n| Alert delivery exceeds 30s SLA | High | Medium | Priority queue, parallel channel delivery, dedicated worker pools |\n| Notification service unavailable | High | Low | Retry with exponential backoff, circuit breaker, fallback channels |\n| Rule evaluation bottleneck at scale | High | Medium | Cache user rules in Redis, batch evaluation, pre-filter by user activity |\n| False positive alerts annoy users | Medium | Medium | Require minimum alert thresholds, provide easy snooze, track opt-out rates |\n| Database write bottleneck | Medium | Low | TimescaleDB for writes, batch inserts, async persistence |\n| Redis cache inconsistency | Medium | Low | Write-through cache, TTL expiration, cache invalidation events |\n| User creates too many rules | Low | Low | Enforce 50 rule limit per user |\n| Data retention violation | High | Low | TimescaleDB automatic retention policy, compliance audit logs |\n| Duplicate alerts | Medium | Medium | Idempotency key on transaction_id + rule_id, deduplication window |\n| Alert fatigue from high volume | Medium | Medium | Per-user rate limiting, alert aggregation, quiet hours support |\n| Queue data loss during failover | High | Low | Redis AOF persistence, cluster replication, recovery from alerts_history |\n\n### 7.1 Latency Optimization Strategy\n\nTo meet the <30 second P99 latency requirement:\n\n1. **Transaction Consumer**: Use consumer group with 10+ partitions for parallelism\n2. **Rule Lookup**: Pre-load active users' rules into Redis at startup\n3. **Alert Generation**: Generate in same process as evaluation (no queue between)\n4. **Priority Queue**: Redis sorted set for O(log N) operations\n5. **Channel Delivery**: Parallel async calls to notification service\n6. **Timeout Handling**: 5 second timeout per channel, fail fast on slow channels\n\n**Latency Budget:**\n| Stage | Target | Cumulative |\n|-------|--------|------------|\n| Transaction consume | 100ms | 100ms |\n| Rule evaluation | 50ms | 150ms |\n| Alert generation | 50ms | 200ms |\n| Queue + dequeue | 100ms | 300ms |\n| Notification delivery | 5000ms | 5300ms |\n| Buffer | 24700ms | 30000ms |\n\n### 7.2 Scalability Design\n\nFor 100M transactions/day (\u22481157 TPS average, \u22485000 TPS peak):\n\n- **Kafka Consumers**: 10 consumer instances \u00d7 10 partitions\n- **Rule Cache**: Redis cluster with 3 nodes, 10GB memory\n- **Database Writes**: Batch alerts in 100ms windows, bulk insert\n- **Notification Workers**: 50 worker threads for channel delivery\n\n### 7.3 Capacity Model\n\n**Assumptions:**\n- 10M users total, ~20% active daily (2M users with transactions)\n- Average 50 transactions/user/day for active users\n- Maximum 50 rules per user (limit enforced)\n- System default rules: 2 per user\n- Average rules per user: 5 (2 system + 3 custom)\n\n**Rule Evaluation Estimates:**\n\n| Scenario | Rules/User | Time/Rule | Total Time | Notes |\n|----------|------------|-----------|------------|-------|\n| Cache hit | 5 | 1ms | 5ms | Rules in Redis |\n| Cache miss | 5 | 20ms | 100ms | DB fetch + cache populate |\n| Worst case (50 rules) | 50 | 1ms | 50ms | Power user, cached |\n\n**Memory Requirements:**\n\n| Component | Calculation | Estimate |\n|-----------|-------------|----------|\n| Rule cache (Redis) | 2M active users \u00d7 5 rules \u00d7 1KB/rule | 10GB |\n| Preferences cache | 2M users \u00d7 200B/user | 400MB |\n| Active snoozes | 100K snoozes \u00d7 500B | 50MB |\n| Rate limit state | 2M users \u00d7 100B | 200MB |\n| **Total Redis** | | **~12GB** |\n\n**Throughput Capacity:**\n\n| Component | Capacity | Calculation |\n|-----------|----------|-------------|\n| Kafka consumers | 10K TPS | 10 instances \u00d7 1K TPS each |\n| Rule engine | 20K TPS | 10 instances \u00d7 2K evaluations/sec |\n| Alert queue | 50K ops/sec | Redis sorted set ops |\n| Notification workers | 5K alerts/sec | 50 workers \u00d7 100 alerts/sec |\n\n**Back-Pressure Handling:**\n\n1. **Consumer lag monitoring**: Alert when Kafka consumer lag > 10 seconds\n2. **Queue depth limits**: If alert queue > 100K items, shed LOW priority alerts\n3. **Circuit breaker**: If notification service error rate > 50%, pause delivery for 30 seconds\n4. **Graceful degradation**: Under extreme load, batch similar alerts (same user, same rule)\n\n### 7.4 Queue Durability\n\nThe alert queue uses Redis with the following high-availability configuration:\n\n**Redis Configuration:**\n- **Cluster mode**: 3-node Redis cluster with automatic failover\n- **Persistence**: AOF (Append Only File) with `appendfsync everysec`\n- **Replication**: Each primary has 1 replica for redundancy\n\n**Recovery Mechanism:**\n\nOn service startup, the alert processor executes a recovery check:\n\n1. Query `alerts_history` for alerts where `created_at > NOW() - 5 minutes` and `delivered_at IS NULL`\n2. For each undelivered alert, check `alert_delivery_records` for pending status\n3. Re-enqueue alerts that have no successful delivery record\n4. Deduplication key (transaction_id + rule_id) prevents duplicate delivery\n\n```python\nasync def recover_pending_alerts():\n    \"\"\"Recover alerts that may have been lost during failover.\"\"\"\n    cutoff = datetime.utcnow() - timedelta(minutes=5)\n    \n    undelivered = await alerts_history.find(\n        created_at__gte=cutoff,\n        delivered_at__isnull=True\n    )\n    \n    for alert in undelivered:\n        if not await delivery_records.has_success(alert.alert_id):\n            await alert_queue.enqueue(alert, dedupe=True)\n            logger.info(f\"Recovered alert {alert.alert_id}\")\n```\n\n**Why Not Kafka-backed Queue:**\n\nA Kafka-backed queue was considered but rejected because:\n1. Alerts should be in the queue for < 1 second typically\n2. Redis with AOF + cluster provides sufficient durability for this use case\n3. Adding Kafka introduces operational complexity and latency\n4. Recovery from alerts_history handles the rare failover scenario\n\n---\n\n## 8. Open Questions\n\n1. ~~**Default Rules**: Should new users get a default set of rules?~~ **RESOLVED**: Yes, users receive system default rules for >$500 and high fraud scores (see Section 3.3).\n\n2. ~~**Rate Limiting**: What is the maximum number of alerts a user should receive per hour/day to prevent alert fatigue?~~ **RESOLVED**: 20 alerts/hour, 100 alerts/day with aggregation for excess (see Section 2.6).\n\n3. ~~**Quiet Hours Channels**: During quiet hours, should alerts be queued for later delivery or silently dropped?~~ **RESOLVED**: CRITICAL alerts delivered immediately; all others queued until quiet hours end (see Section 2.5).\n\n4. **Snooze Maximum Duration**: What is the maximum snooze duration allowed? Should there be limits to prevent users from accidentally snoozing for too long?\n\n5. **Alert Aggregation**: For users receiving many alerts (e.g., business accounts), should we aggregate multiple alerts into a daily digest?\n\n6. **Notification Service SLA**: What are the latency and availability guarantees of the existing notification service?\n\n7. **Multi-Account Support**: Can a user have alerts for multiple accounts, and if so, should rules be per-account or global?\n\n8. **Regulatory Requirements**: Are there specific compliance requirements (PCI-DSS, GDPR) that affect how we store or transmit transaction data in alerts?\n\n9. **Fallback Channel**: If primary notification channel fails, should we automatically try secondary channels or wait for retry?\n\n---\n\n## 9. Appendix\n\n### 9.1 Sample Alert Templates\n\n**Push Notification:**\n```\nTitle: Large Transaction Alert\nBody: $750.00 purchase at Amazon.com detected\n```\n\n**Push Notification (Suspicious):**\n```\nTitle: \u26a0\ufe0f Suspicious Activity Detected\nBody: Unusual transaction of $150.00 at Foreign Merchant flagged for review\n```\n\n**Push Notification (Rate Limited Summary):**\n```\nTitle: Transaction Alert Summary\nBody: You have 15 new transaction alerts. Tap to view details.\n```\n\n**SMS:**\n```\n[YourBank] Alert: $750.00 at Amazon.com. Not you? Call 1-800-XXX-XXXX\n```\n\n**Email:**\n```\nSubject: Transaction Alert - $750.00 at Amazon.com\n\nDear [Customer Name],\n\nWe detected a transaction on your account:\n\nAmount: $750.00\nMerchant: Amazon.com\nDate: December 15, 2025 at 10:25 AM EST\nCard: ****1234\n\nIf you did not make this transaction, please contact us immediately.\n\nBest regards,\nYour Bank Security Team\n```\n\n### 9.2 Configuration Schema\n\n```yaml\nalerts:\n  # Processing settings\n  consumer:\n    kafka_topic: \"transactions.processed\"\n    consumer_group: \"alerts-processor\"\n    partitions: 10\n    max_poll_records: 500\n\n  # Caching settings\n  cache:\n    redis_cluster: \"redis://alerts-cache:6379\"\n    rules_ttl_seconds: 300\n    preferences_ttl_seconds: 60\n\n  # Delivery settings\n  delivery:\n    max_retries: 3\n    retry_backoff_seconds: [1, 5, 15]\n    channel_timeout_seconds: 5\n    parallel_channels: true\n\n  # Rate limiting\n  rate_limits:\n    per_user_hourly: 20\n    per_user_daily: 100\n    per_channel_hourly: 10\n    critical_exempt: true\n\n  # Quiet hours\n  quiet_hours:\n    critical_bypass: true\n    max_queued_alerts: 100\n    aggregation_threshold: 10\n\n  # Limits\n  limits:\n    max_rules_per_user: 50\n    max_active_snoozes: 5\n    max_snooze_duration_hours: 168  # 1 week\n    min_alert_amount: 0.01\n\n  # System default rules\n  defaults:\n    large_transaction_threshold: 500.00\n    fraud_score_threshold: 0.7\n\n  # Queue durability\n  queue:\n    redis_aof_enabled: true\n    redis_cluster_nodes: 3\n    recovery_window_minutes: 5\n\n  # Retention\n  retention:\n    alert_history_days: 90\n    delivery_records_days: 30\n```\n\n### 9.3 Monitoring Metrics\n\n| Metric | Type | Labels | Description |\n|--------|------|--------|-------------|\n| `alerts_transactions_consumed_total` | Counter | - | Total transactions consumed |\n| `alerts_rules_evaluated_total` | Counter | rule_type | Total rule evaluations by type |\n| `alerts_generated_total` | Counter | priority, rule_type | Alerts generated by priority and rule type |\n| `alerts_delivered_total` | Counter | channel, status | Delivery outcomes |\n| `alerts_snoozed_total` | Counter | channel | Alerts dropped due to snooze |\n| `alerts_quiet_hours_queued_total` | Counter | priority | Alerts queued for quiet hours |\n| `alerts_rate_limited_total` | Counter | limit_type | Alerts that hit rate limits |\n| `alerts_aggregated_total` | Counter | - | Summary notifications sent |\n| `alerts_delivery_latency_seconds` | Histogram | channel | End-to-end delivery latency |\n| `alerts_queue_depth` | Gauge | priority | Current queue depth |\n| `alerts_quiet_hours_queue_depth` | Gauge | - | Alerts waiting for quiet hours to end |\n| `alerts_rule_evaluation_duration_seconds` | Histogram | - | Rule evaluation time |\n| `alerts_notification_duration_seconds` | Histogram | channel | Notification service call time |\n| `alerts_active_snoozes` | Gauge | - | Currently active snooze periods |\n| `alerts_cache_hit_ratio` | Gauge | cache_type | Redis cache hit rate |\n| `alerts_user_dismissed_total` | Counter | rule_type | User dismissed/acknowledged alerts |\n| `alerts_user_reported_incorrect_total` | Counter | rule_type | User reported alert as false positive |\n| `alerts_user_action_taken_total` | Counter | action_type | User actions (blocked_card, reported_fraud, dismissed) |\n| `alerts_recovered_total` | Counter | - | Alerts recovered after restart/failover |\n\n**Note on False Positive Measurement:** The `alerts_user_reported_incorrect_total` metric tracks when users explicitly mark an alert as incorrect. This data should be exported to a downstream analytics system for calculating the false positive rate against actual dispute outcomes. The alerting system emits these events but does not compute the aggregate metric.\n\n**Note on Fraud Loss Measurement:** The `alerts_user_action_taken_total` metric tracks user responses to alerts (blocked card, reported fraud, dismissed). To measure fraud loss reduction (PRD goal: 40%), this data must be joined with dispute outcomes and financial loss data in a downstream analytics system. This is a cross-functional initiative requiring coordination with fraud operations and finance teams.\n<<<SPEC_END>>>\n\n<<<RUBRIC_START>>>\n{\n  \"round\": 2,\n  \"previous_scores\": {\"clarity\": 0.78, \"coverage\": 0.72, \"architecture\": 0.75, \"risk\": 0.65},\n  \"current_scores\": {\"clarity\": 0.85, \"coverage\": 0.82, \"architecture\": 0.83, \"risk\": 0.80},\n  \"issues_accepted\": 2,\n  \"issues_rejected\": 0,\n  \"issues_deferred\": 1,\n  \"issues_partial\": 1,\n  \"continue_debate\": true,\n  \"ready_for_approval\": false,\n  \"meta\": {\n    \"recommend_human_review\": false,\n    \"review_reason\": null\n  },\n  \"dispute_resolutions\": []\n}\n<<<RUBRIC_END>>>",
  "session_id": "d3459dea-23a8-45b9-84a3-11c86666c807",
  "total_cost_usd": 0.5947220000000001,
  "usage": {
    "input_tokens": 2,
    "cache_creation_input_tokens": 19162,
    "cache_read_input_tokens": 17817,
    "output_tokens": 18220,
    "server_tool_use": {
      "web_search_requests": 0,
      "web_fetch_requests": 0
    },
    "service_tier": "standard",
    "cache_creation": {
      "ephemeral_1h_input_tokens": 0,
      "ephemeral_5m_input_tokens": 19162
    }
  },
  "modelUsage": {
    "claude-haiku-4-5-20251001": {
      "inputTokens": 981,
      "outputTokens": 208,
      "cacheReadInputTokens": 0,
      "cacheCreationInputTokens": 0,
      "webSearchRequests": 0,
      "costUSD": 0.0020210000000000002,
      "contextWindow": 200000
    },
    "claude-opus-4-5-20251101": {
      "inputTokens": 1111,
      "outputTokens": 18339,
      "cacheReadInputTokens": 17817,
      "cacheCreationInputTokens": 19162,
      "webSearchRequests": 0,
      "costUSD": 0.592701,
      "contextWindow": 200000
    }
  },
  "permission_denials": [],
  "uuid": "c4048454-6d78-498a-8f61-7f1942cfc626"
}