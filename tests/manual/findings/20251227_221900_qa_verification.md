# QA Agent Bug Fix Sprint

**Date:** 2025-12-27T22:19:00Z
**Verifier:** Claude Opus 4.5
**Overall Result:** PARTIAL PASS (functional but with bugs)

---

## Instructions for Bug Fix Team

This document serves as the prompt for a team of AI agents to fix the bugs discovered during QA verification. Each bug should be fixed using **Test-Driven Development (TDD)** in an isolated **git worktree**.

### Workflow

1. **Create a worktree** for the bug fix branch
2. **Confirm root cause** - Read the relevant code, trace the bug, and explain WHY it happens before writing any fix
3. **Write failing tests first** that expose the bug
4. **Implement the fix** to make tests pass
5. **Run full test suite** to ensure no regressions
6. **Create PR** with root cause analysis and test evidence

> **IMPORTANT:** Do not proceed to step 3 until you have written a root cause analysis explaining the exact line(s) causing the bug and why the current code is wrong.

### Worktree Setup

```bash
cd /Users/philipjcortes/Desktop/swarm-attack-qa-agent

# Create single worktree for all QA bug fixes
git worktree add ../worktrees/fix-qa-bugs -b fix/qa-agent-bugs
cd ../worktrees/fix-qa-bugs
```

---

## Bug #1: QASession.from_dict() Context Restoration Incomplete

**Priority:** CRITICAL
**File:** `swarm_attack/qa/models.py:292-327`

### Problem

The `QASession.from_dict()` method only restores a subset of the context fields, losing important data on round-trip serialization.

**Missing fields:**
- `target_endpoints`
- `base_url`
- `environment`
- `git_diff`
- `spec_content`
- `related_tests`

### Root Cause Analysis

**Before fixing, confirm:**
- [ ] I have read `swarm_attack/qa/models.py` lines 292-327
- [ ] Root cause: _[Agent fills this in before proceeding]_

### TDD Steps

#### Step 1: Write Failing Test

Create/update `tests/unit/qa/test_models.py`:

```python
def test_qa_session_roundtrip_preserves_all_context_fields():
    """Test that QASession serialization preserves all context fields."""
    from swarm_attack.qa.models import (
        QASession, QAContext, QAEndpoint, QAResult,
        QATrigger, QADepth, QAStatus, QARecommendation
    )

    # Create session with ALL context fields populated
    context = QAContext(
        feature_id="test-feature",
        issue_number=123,
        bug_id="bug-456",
        spec_path="/path/to/spec.md",
        target_files=["src/api.py", "src/models.py"],
        target_endpoints=[
            QAEndpoint(method="GET", path="/api/users", auth_required=True),
            QAEndpoint(method="POST", path="/api/users", auth_required=True),
        ],
        base_url="http://localhost:8765",
        environment={"ENV": "test", "DEBUG": "true"},
        git_diff="diff --git a/file.py",
        spec_content="# Spec content here",
        related_tests=["test_api.py", "test_models.py"],
    )

    session = QASession(
        session_id="qa-20251227-123456",
        trigger=QATrigger.USER_COMMAND,
        depth=QADepth.STANDARD,
        status=QAStatus.COMPLETED,
        context=context,
        result=QAResult(
            tests_run=5,
            tests_passed=4,
            tests_failed=1,
            recommendation=QARecommendation.WARN,
        ),
    )

    # Round-trip through serialization
    data = session.to_dict()
    restored = QASession.from_dict(data)

    # Assert ALL context fields are preserved
    assert restored.context.feature_id == "test-feature"
    assert restored.context.issue_number == 123
    assert restored.context.bug_id == "bug-456"
    assert restored.context.spec_path == "/path/to/spec.md"
    assert restored.context.target_files == ["src/api.py", "src/models.py"]
    assert len(restored.context.target_endpoints) == 2
    assert restored.context.target_endpoints[0].method == "GET"
    assert restored.context.target_endpoints[0].path == "/api/users"
    assert restored.context.target_endpoints[0].auth_required == True
    assert restored.context.base_url == "http://localhost:8765"
    assert restored.context.environment == {"ENV": "test", "DEBUG": "true"}
    assert restored.context.git_diff == "diff --git a/file.py"
    assert restored.context.spec_content == "# Spec content here"
    assert restored.context.related_tests == ["test_api.py", "test_models.py"]
```

#### Step 2: Run Test (Should Fail)

```bash
cd ../worktrees/fix-qa-context-serialization
PYTHONPATH=. pytest tests/unit/qa/test_models.py::test_qa_session_roundtrip_preserves_all_context_fields -v
```

#### Step 3: Implement Fix

Update `swarm_attack/qa/models.py` line 298-303:

```python
@classmethod
def from_dict(cls, data: dict[str, Any]) -> QASession:
    trigger = QATrigger(data["trigger"])
    depth = QADepth(data["depth"])
    status = QAStatus(data["status"])
    context_data = data.get("context", {})

    # Restore target_endpoints from serialized form
    target_endpoints = [
        QAEndpoint(
            method=e.get("method", "GET"),
            path=e.get("path", ""),
            auth_required=e.get("auth_required", False),
        )
        for e in context_data.get("target_endpoints", [])
    ]

    context = QAContext(
        feature_id=context_data.get("feature_id"),
        issue_number=context_data.get("issue_number"),
        bug_id=context_data.get("bug_id"),
        spec_path=context_data.get("spec_path"),
        target_files=context_data.get("target_files", []),
        target_endpoints=target_endpoints,
        base_url=context_data.get("base_url"),
        environment=context_data.get("environment", {}),
        git_diff=context_data.get("git_diff"),
        spec_content=context_data.get("spec_content"),
        related_tests=context_data.get("related_tests", []),
    )
    # ... rest of method unchanged
```

#### Step 4: Run Test (Should Pass)

```bash
PYTHONPATH=. pytest tests/unit/qa/test_models.py::test_qa_session_roundtrip_preserves_all_context_fields -v
```

#### Step 5: Run Full Test Suite

```bash
PYTHONPATH=. pytest tests/unit/qa/ -v
```

### Acceptance Criteria

- [ ] Test `test_qa_session_roundtrip_preserves_all_context_fields` passes
- [ ] All existing tests still pass
- [ ] Manual verification: `swarm-attack qa report <session> --json` shows `base_url` and `target_endpoints`

---

## Bug #2: Health Check Runs Zero Tests

**Priority:** MODERATE
**File:** `swarm_attack/qa/orchestrator.py:262-302`

### Problem

The `health_check()` method completes successfully but runs 0 tests, even when a valid `base_url` is provided.

### Root Cause Analysis

**Before fixing, confirm:**
- [ ] I have read `swarm_attack/qa/orchestrator.py` lines 262-302
- [ ] Root cause: _[Agent fills this in before proceeding]_

### TDD Steps

#### Step 1: Write Failing Test

Create/update `tests/unit/qa/test_orchestrator.py`:

```python
def test_health_check_runs_at_least_one_test():
    """Health check should run at least one test when base_url is provided."""
    from swarm_attack.qa.orchestrator import QAOrchestrator
    from swarm_attack.qa.models import QAStatus
    from unittest.mock import MagicMock

    config = MagicMock()
    config.repo_root = "/tmp/test"

    orch = QAOrchestrator(config)

    # Mock the behavioral agent to return a real result
    orch.behavioral_agent.run = MagicMock(return_value=MagicMock(
        success=True,
        output={
            "tests_run": 1,
            "tests_passed": 1,
            "tests_failed": 0,
            "findings": [],
        }
    ))

    session = orch.health_check(base_url="http://localhost:8765")

    assert session.status == QAStatus.COMPLETED
    assert session.result is not None
    assert session.result.tests_run >= 1, "Health check should run at least 1 test"
    assert session.context.base_url == "http://localhost:8765"


def test_health_check_discovers_health_endpoint():
    """Health check should at minimum test /health endpoint."""
    from swarm_attack.qa.orchestrator import QAOrchestrator
    from swarm_attack.qa.models import QAEndpoint
    from unittest.mock import MagicMock

    config = MagicMock()
    config.repo_root = "/tmp/test"

    orch = QAOrchestrator(config)

    session = orch.health_check(base_url="http://localhost:8765")

    # Should have at least /health endpoint in context
    assert len(session.context.target_endpoints) >= 1
    health_paths = [e.path for e in session.context.target_endpoints]
    assert "/health" in health_paths or any("/health" in p for p in health_paths)
```

#### Step 2: Implement Fix

Update `swarm_attack/qa/orchestrator.py` `health_check()` method to:

1. Add default `/health` endpoint to context
2. Optionally discover endpoints via OpenAPI if available

```python
def health_check(self, base_url: Optional[str] = None) -> QASession:
    """Run shallow health check on all endpoints."""
    session_id = self._generate_session_id()

    # Default health endpoints to check
    default_endpoints = [
        QAEndpoint(method="GET", path="/health"),
        QAEndpoint(method="GET", path="/api/health"),
        QAEndpoint(method="GET", path="/healthz"),
    ]

    context = QAContext(
        base_url=base_url,
        target_endpoints=default_endpoints,
    )
    # ... rest of method
```

### Acceptance Criteria

- [ ] Test `test_health_check_runs_at_least_one_test` passes
- [ ] Test `test_health_check_discovers_health_endpoint` passes
- [ ] Manual: `swarm-attack qa health --base-url http://localhost:8765` shows `Tests: N run` where N >= 1

---

## Bug #3: Severity Counts Not Updated

**Priority:** MINOR
**File:** `swarm_attack/qa/orchestrator.py:429-512`

### Problem

The `_aggregate_results()` method calculates severity counts, but when a critical finding is present, the JSON shows `critical_count: 0`.

### Root Cause Analysis

**Before fixing, confirm:**
- [ ] I have read `swarm_attack/qa/orchestrator.py` lines 429-512
- [ ] Root cause: _[Agent fills this in before proceeding]_

### TDD Steps

#### Step 1: Write Failing Test

```python
def test_aggregate_results_counts_critical_findings():
    """Aggregated results should correctly count findings by severity."""
    from swarm_attack.qa.orchestrator import QAOrchestrator
    from swarm_attack.qa.models import QAFinding, QARecommendation
    from unittest.mock import MagicMock

    config = MagicMock()
    config.repo_root = "/tmp/test"

    orch = QAOrchestrator(config)

    # Create agent results with findings
    critical_finding = QAFinding(
        finding_id="BT-001",
        severity="critical",
        category="behavioral",
        endpoint="GET /api/error",
        test_type="happy_path",
        title="Server error",
        description="500 error",
        expected={"status": 200},
        actual={"status": 500},
        evidence={},
        recommendation="Fix it",
    )

    agent_results = {
        "behavioral": {
            "tests_run": 1,
            "tests_passed": 0,
            "tests_failed": 1,
            "findings": [critical_finding],
        }
    }

    result = orch._aggregate_results(agent_results)

    assert result.critical_count == 1, f"Expected 1 critical, got {result.critical_count}"
    assert result.recommendation == QARecommendation.BLOCK
```

#### Step 2: Debug and Fix

The issue is likely that findings from agent output aren't being converted to `QAFinding` objects properly, or the count logic runs before findings are processed.

### Acceptance Criteria

- [ ] Test `test_aggregate_results_counts_critical_findings` passes
- [ ] Manual: `swarm-attack qa report <session> --json | jq '.result.critical_count'` matches actual count

---

## Bug #4: Test Count Doesn't Scale with Depth

**Priority:** MINOR
**Files:** `swarm_attack/qa/agents/behavioral.py`, `swarm_attack/qa/agents/contract.py`

### Problem

Both `shallow` and `standard` depth run only 1 test. Standard depth should run more comprehensive tests.

### Root Cause Analysis

**Before fixing, confirm:**
- [ ] I have read `swarm_attack/qa/agents/behavioral.py` and `contract.py`
- [ ] Root cause: _[Agent fills this in before proceeding]_

### TDD Steps

#### Step 1: Write Failing Test

```python
def test_standard_depth_runs_more_tests_than_shallow():
    """Standard depth should run more tests than shallow."""
    from swarm_attack.qa.orchestrator import QAOrchestrator
    from swarm_attack.qa.models import QADepth, QAContext, QAEndpoint
    from unittest.mock import MagicMock

    config = MagicMock()
    config.repo_root = "/tmp/test"

    orch = QAOrchestrator(config)

    context = QAContext(
        base_url="http://localhost:8765",
        target_endpoints=[QAEndpoint(method="GET", path="/api/users")],
    )

    # Run shallow
    shallow_results = orch.dispatch_agents(QADepth.SHALLOW, context)
    shallow_tests = shallow_results.get("behavioral", {}).get("tests_run", 0)

    # Run standard
    standard_results = orch.dispatch_agents(QADepth.STANDARD, context)
    standard_behavioral = standard_results.get("behavioral", {}).get("tests_run", 0)
    standard_contract = standard_results.get("contract", {}).get("contracts_checked", 0)
    standard_total = standard_behavioral + standard_contract

    assert standard_total > shallow_tests, \
        f"Standard ({standard_total}) should run more tests than shallow ({shallow_tests})"
```

### Acceptance Criteria

- [ ] Test `test_standard_depth_runs_more_tests_than_shallow` passes
- [ ] Manual: Standard depth runs 2+ tests per endpoint (behavioral + contract)

---

## Execution Order

Fix bugs in this order (by priority and dependencies):

1. **Bug #1** (CRITICAL) - Fixes data persistence, blocks other debugging
2. **Bug #3** (MINOR) - Quick fix, helps verify Bug #2 and #4
3. **Bug #2** (MODERATE) - Health check functionality
4. **Bug #4** (MINOR) - Depth scaling

---

## Verification After Fixes

After all bugs are fixed, re-run the manual verification:

```bash
# Start test server
python -c "
from fastapi import FastAPI, HTTPException
import uvicorn
app = FastAPI()
@app.get('/health')
def health(): return {'status': 'healthy'}
@app.get('/api/users')
def users(): return {'users': []}
@app.get('/api/error')
def error(): raise HTTPException(500, 'Error')
uvicorn.run(app, port=8765)
" &

# Run verification
swarm-attack qa health --base-url http://localhost:8765
swarm-attack qa test "/api/users" --base-url http://localhost:8765 --depth shallow
swarm-attack qa test "/api/users" --base-url http://localhost:8765 --depth standard
swarm-attack qa test "/api/error" --base-url http://localhost:8765
swarm-attack qa report --json

# Verify round-trip
python -c "
from swarm_attack.qa.orchestrator import QAOrchestrator
from swarm_attack.qa.models import QASession, QADepth
from swarm_attack.cli.common import get_config_or_default

config = get_config_or_default()
orch = QAOrchestrator(config)
session = orch.test('/api/users', QADepth.STANDARD, base_url='http://localhost:8765')
d = session.to_dict()
restored = QASession.from_dict(d)
assert restored.context.base_url == 'http://localhost:8765', 'Bug #1 not fixed'
assert session.result.tests_run >= 1, 'Bug #2 not fixed'
print('All fixes verified!')
"
```

---

## Historical Notes

| Date | Verifier | Result | Notes |
|------|----------|--------|-------|
| 2024-12-27 | Claude | PASS | Initial verification after implementing 10.2/10.5 tests |
| 2025-12-27 | Claude Opus 4.5 | PARTIAL | Found 4 bugs, documented for TDD fix |

---

*This document is a prompt for AI agents to fix bugs via TDD in worktrees.*
